{
  "hash": "caa176eb486daac0ad2a6c81236cfb0c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Using AWS + GitHub Actions to automate Shiny app updates and redeployments\"\ndescription: |\n  the personal project that keeps on giving (new skills)\nauthor:\n  - name: Samantha Csik\n    url: https://samanthacsik.github.io/\n    orcid: 0000-0002-5300-3075\ndate: 2024-10-16\ncitation: \n  url: https://samanthacsik.github.io/posts/automating-shiny-updates/\ncategories: [Shiny, AWS-s3, GitHub-Actions, Strava]\nimage: media/s3-GHA.png\nbibliography: references.bib\ndraft: true\ndraft-mode: linked\n---\n\n\n\n## A brief history of my Strava Dashboard journey\n\n- for learning shiny\n- helped refresh other skills e.g. leaflet, plotly, for loops\n- updating it is a minor pain, but a pain nonetheless\n- entering new territory\n- had literally no idea where to begin with this one, so I talked to Brendan who helped me outline some concrete steps to tackle\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](media/issue-comment.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n::: {.center-text .body-text-s}\n*The comment that set me on my path towards shiny app automation!*\n:::\n\n## Creating, writing to, and reading from an Amazon S3 Bucket \n\nMy initial thought was \"yeah S3, no way...\" That felt like way too big of a mountain to climb and also -- at the time -- felt tangential to my actual goal of grabbing my latest data from strava, then redeploying my app to shinyapps.io with said new data. But, one very quick Google search led me to one of my favorite bloggers and an excelled blog post: [Using Amazong S3 with R](https://blog.djnavarro.net/posts/2022-03-17_using-aws-s3-in-r/), by [Danielle Navarro] (https://djnavarro.net/). So we decided to climb the damn mountain (and spoiler, it was pretty darn easy!).\n\nI basically followed Danielle's amazing instructions to a T (see [this section](https://blog.djnavarro.net/posts/2022-03-17_using-aws-s3-in-r/#accounts-and-credentials))\n\n### 1. Get yourself an AWS account\n\nYou *do* need to provide a credit card. Consider setting up [Amazon CloudWatch](https://aws.amazon.com/cloudwatch/) to monitor usage so that you don't accidentally incur unanticipated charges. (come back to this [reddit thread](https://www.reddit.com/r/aws/comments/gu1u9t/how_to_avoid_unexpected_charges_when_using_aws/))\n\n### 2. Allow R to interact with S3\n\nFollow [Danielle's instructions](https://blog.djnavarro.net/posts/2022-03-17_using-aws-s3-in-r/#creating-credentials)\n\n### 3. Store AWS credentials in R (and a password manager)\n\nAgain, following [Danielle's instructions](https://blog.djnavarro.net/posts/2022-03-17_using-aws-s3-in-r/#storing-your-aws-credentials-in-r)\n\n- [How to Use GitHub Actions with R to Run Code Automatically](https://rfortherestofus.com/2023/05/github-actions), by [David Keyes](https://dgkeyes.com/)\n\n### 4. Manipulate your S3 storage from R\n\n#### Create a new bucket\n\n#### Write a data file to your bucket",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}